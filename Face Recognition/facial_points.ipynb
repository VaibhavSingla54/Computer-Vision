{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector= dlib.get_frontal_face_detector()\n",
    "points_detector= dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "image= cv2.imread('people2.jpg')\n",
    "\n",
    "face_detection= face_detector(image, 1)\n",
    "for face in face_detection:\n",
    "    points= points_detector(image, face)\n",
    "    for point in points.parts():\n",
    "        cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)\n",
    "\n",
    "    l,t,r,b= face.left(),face.top(), face.right(), face.bottom()\n",
    "    cv2.rectangle(image, (l,t), (r,b), (0,255,0),2)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector= dlib.get_frontal_face_detector()\n",
    "points_detector= dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "face_descriptor_extractor= dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "index= {}\n",
    "idx=0\n",
    "face_descriptors= None\n",
    "\n",
    "paths= [os.path.join('yalefaces/train',f) for f in os.listdir('yalefaces/train')]\n",
    "for path in paths:\n",
    "    image= Image.open(path).convert('RGB')\n",
    "    image_np= np.array(image, 'uint8')\n",
    "    face_detection = face_detector(image_np,1)\n",
    "    for face in face_detection:\n",
    "        l,t,r,b= face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image_np, (l,t), (r,b), (0,255,0), 2)\n",
    "\n",
    "        points= points_detector(image_np, face)\n",
    "        for point in points.parts():\n",
    "            cv2.circle(image_np, (point.x,point.y), 2, (0,255,0), 1)\n",
    "\n",
    "        face_descriptor= face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "        face_descriptor= [f for f in face_descriptor]\n",
    "        face_descriptor= np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor= face_descriptor[np.newaxis, :]\n",
    "        if face_descriptors is None:\n",
    "            face_descriptors= face_descriptor\n",
    "        else:\n",
    "            face_descriptors= np.concatenate((face_descriptors, face_descriptor), axis=0)\n",
    "        index[idx]= path\n",
    "        idx+=1\n",
    "    \n",
    "    # cv2.imshow('Image',image_np)\n",
    "    # cv2.waitKey(delay = 1)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(face_descriptors[103]- face_descriptors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 11 11 12 12\n",
      " 13 13 14 14 15 15]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 11 11 12 12\n",
      " 13 13 14 14 15 15]\n"
     ]
    }
   ],
   "source": [
    "threshold= 0.5\n",
    "predictions= []\n",
    "expected_outputs= []\n",
    "\n",
    "paths= [os.path.join('yalefaces/test',f )for f in os.listdir('yalefaces/test')]\n",
    "for path in paths:\n",
    "    image= Image.open(path).convert('RGB')\n",
    "    image_np= np.array(image, 'uint8')\n",
    "    face_detection= face_detector(image_np, 1)\n",
    "    for face in face_detection:\n",
    "        points= points_detector(image_np, face)\n",
    "        face_descriptor= face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "        face_descriptor= [f for f in face_descriptor]\n",
    "        face_descriptor= np.asarray(face_descriptor, dtype= np.float64)\n",
    "        face_descriptor= face_descriptor[np.newaxis, :]\n",
    "\n",
    "        distances= np.linalg.norm(face_descriptor- face_descriptors,axis=1 )\n",
    "        min_index= np.argmin(distances)\n",
    "        min_distance= distances[min_index]\n",
    "        \n",
    "        if min_distance<=threshold:\n",
    "            name_pred= int(os.path.split(index[min_index])[1].split('.')[0].replace('subject',''))\n",
    "        else:\n",
    "            name_pred= 'Not Identified'\n",
    "\n",
    "        name_real= int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n",
    "        predictions.append(name_pred)\n",
    "        expected_outputs.append(name_real)\n",
    "\n",
    "        cv2.putText(image_np, 'Pred: '+ str(name_pred), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "        cv2.putText(image_np, 'Pred: '+ str(name_real), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "\n",
    "predictions =np.array(predictions)\n",
    "expected_outputs= np.array(expected_outputs)\n",
    "print(predictions)\n",
    "print(expected_outputs)\n",
    "    \n",
    "    # cv2.imshow('Image', image_np)\n",
    "    # cv2.waitKey(delay= 1)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix \n",
    "acc= accuracy_score(expected_outputs, predictions)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
